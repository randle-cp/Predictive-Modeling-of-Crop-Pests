k<-NClayers[11]
l<-NClayers[12]
m<-NClayers[13]
n<-NClayers[14]
gam <- gam(pa ~ "a" + b + c +
d + e + f + g + h + i + j+ k + l + m + n,                      ,
family = binomial(link = "logit"), data=train_data)
a<-NClayers[1]
b<-NClayers[2]
c<-NClayers[3]
d<-NClayers[4]
e<-NClayers[5]
f<-NClayers[6]
g<-NClayers[7]
h<-NClayers[8]
i<-NClayers[9]
j<-NClayers[10]
k<-NClayers[11]
l<-NClayers[12]
m<-NClayers[13]
n<-NClayers[14]
gam <- gam(pa ~ 'a' + b + c +
d + e + f + g + h + i + j+ k + l + m + n,                      ,
family = binomial(link = "logit"), data=train_data)
a<-NClayers[1]
b<-NClayers[2]
c<-NClayers[3]
d<-NClayers[4]
e<-NClayers[5]
f<-NClayers[6]
g<-NClayers[7]
h<-NClayers[8]
i<-NClayers[9]
j<-NClayers[10]
k<-NClayers[11]
l<-NClayers[12]
m<-NClayers[13]
n<-NClayers[14]
gam <- gam(pa ~ as. character(a) + b + c +
gam <- gam(pa ~ as.character(a) + b + c +
d + e + f + g + h + i + j+ k + l + m + n,                      ,
family = binomial(link = "logit"), data=train_data)
z<-as.character(a)
gam <- gam(pa ~ as.character(a) + b + c +
d + e + f + g + h + i + j+ k + l + m + n,                      ,
family = binomial(link = "logit"), data=train_data)
make.formula <- function(pnam) {
formula <- c()
for (i in 1:pnam) {
if (i == 1) {
formula <- paste(formula, names(d)[i], '~')}
else if (i == pnam) {
formula <- paste(formula, names(d)[i], '')
}
else {
formula <- paste(formula, names(d)[i], '+')}
}
return(formula)
}
formulas <- lapply(seq(2, length(d)), make.formula)
formulas <- lapply(formulas, as.formula)
make.formula <- function(howfar) {
formula <- c()
for (i in 1:howfar) {
if (i == 1) {
formula <- paste(formula, names(d)[i], '~')}
else if (i == howfar) {
formula <- paste(formula, names(d)[i], '')
}
else {
formula <- paste(formula, names(d)[i], '+')}
}
return(formula)
}
formulas <- lapply(seq(2, length(d)), make.formula)
formulas <- lapply(formulas, as.formula)
return(formula)
gam <- gam(pa ~ Mean_durnal_temp_range + Temp_Seasonality + MaxTemp_WarmestWeek +
Mean_temp_wettest_q + Ann_.precip + Precip_Seasonality + Precip_warmest_q + Hghest_weekly_rad + Rad_driest_q + Rad_coldest_q+ Moisture_seasonality + Mean_moisture_coldest_q + Elev + human_impact,                      ,
family = binomial(link = "logit"), data=train_data)
summary(gam)
GAMpreds <- predict(predictors, gam, type = 'response')
writeRaster(GAMpreds, filename = paste0(genus,"_",species,"_GAM.tif"), overwrite=TRUE)
plot(GAMpreds, main=c(genus,species,'GAM/Binary'),col=warm(100), zlim=c(0,1))
points(pres_test, col='white', cex =.4, pch=3)
samp1 <- spsample(pol, 10000, type='random', iter=25)
#and get the cell numbers from the raster stack (right to left, up to down)
cells <- cellFromXY(predictors, samp1)
#and transform each of those to the center of its cell.
background_train <- xyFromCell(predictors, cells)
#You'll get a warning saying that your CRS object has lost a comment. This is unimportant and can be ignored.
Sys.setenv(JAVA_HOME='/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home')
Sys.setenv(JAVA_HOME='/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home')
Sys.setenv(JAVA_HOME='/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home')
maxent()
me_model <- maxent(predictors, pres_train, a=background_train)
knitr::opts_chunk$set(echo = TRUE)
library(dismo)
library(sp)
library(raster)
library(stats)
library(dplyr)
library(knitr)
library(rgeos)
library(maptools)
library(rgdal)
library(ecospat)
library(usdm)
library(mgcv)
genus<-"Autographa"
species<-"gamma"
sdmdata<-read.csv(file=paste0("Autographa gamma clean.csv"))
##and visualize the data
#first lets get the extent of the data (the coordinates of the smallest box needed to encapsulate the data)  To do this I first need to convert sdmdata into a spatial points dataframe with the same crs as "wrldsmpl", a giant spatial polygons data frame available from maptools
sdmdataframe<-data.frame(sdmdata)
data(wrld_simpl)
coordinates(sdmdataframe) <- ~lon+lat
crs(sdmdataframe) <- crs(wrld_simpl)
#And then extract the extent
e<-extent(sdmdataframe)
xmin<-xmin(e)
xmax<-xmax(e)
ymin<-ymin(e)
ymax<-ymax(e)
# and then plot a map and add the points from sdmdata
plot(wrld_simpl, xlim=c(xmin,xmax), ylim=c(ymin,ymax), axes=TRUE, col="light yellow")
box()
points(sdmdata$lon, sdmdata$lat, col='red', cex=0.75)
#let's make sdmdata into a dataframe
data(wrld_simpl)
coordinates(sdmdata) <- ~lon+lat
crs(sdmdata) <- crs(wrld_simpl)
#let's extract just the coordinates
presence <- coordinates(sdmdata)
#First we'll make a random list of integers from 1-5 as long as our presence data. Setting the seed results in a repeatable random process
set.seed(0)
#now make a list as long as the number of rows in presence consisting of a random series of integers from 1-5
group <- kfold(presence, 5)
#Then we want to use this to retrieve the number of the rows in the presence data that are associated with the number 1 in our group index.
test_indices <- as.integer(row.names(presence[group == 1, ]))
#and create a new list of coordinates including only those rows that are NOT in test indices. These are all the row numbers NOT corresponding with the test_indices (which is ~80% of the data).
pres_train <- presence[-test_indices,]
#and those that do correspond with test indices (20%) of the data
pres_test <- presence[group ==1,]
#first presdata_train
outdata<-data.frame(pres_train)
colnames(outdata)<-c("lon","lat")
write.csv(outdata, file=paste0(genus,"_",species,"_train.csv"), row.names=FALSE)
#and then presdata_test
outdata<-data.frame(pres_test)
colnames(outdata)<-c("lon","lat")
write.csv(outdata, file=paste0(genus,"_",species,"_test.csv"), row.names=FALSE)
predictors<-stack('Climond_elev_HI.tif')
bands<-c("Ann_mean_temp",	"Mean_durnal_temp_range",	"Isothermality",	"Temp_Seasonality",	"MaxTemp_WarmestWeek",	"MinTemp_ColdestWeek",	"Temp_Annual_Range",	"Mean_temp_wettest_q",	"Mean_temp_driest_q",	"Mean_temp_warmiest_q",	"Mean_temp_coldest_q",	"Ann_ precip",	"Precip_driest_week",	"Precip_wettest_week",	"Precip_Seasonality",	"Precip_wettest_q",	"Precip_driest_q",	"Precip_warmest_q",	"Precip_coldest_q",	"Ann_mean_rad",	"Hghest_weekly_rad",	"Lowest_weekly_rad",	"Rad_seasonality",	"Rad_wettest_q",	"Rad_driest_q",	"Rad_warmest_q",	"Rad_coldest_q",	"Ann_mean_moisture",	"Highsets_weekly_moisture",	"Lowest_weekly_moisture",	"Moisture_seasonality",	"Mean_moisture_wettest_q",	"Mean_moisture_driest_q",	"Mean_moisture_warmest_q",	"Mean_moisture_coldest_q",	"Elev", 'human_impact')
names(predictors)<-bands
cool<-colorRampPalette(c('gray','green','dark green',"blue"))
warm<-colorRampPalette(c('yellow', 'orange', 'red', 'brown', 'black'))
plot(predictors[["Ann_mean_temp"]], col=warm(100))
#extract environmental data using the points in sdmdata
env_data<-extract(predictors,sdmdata)
#give names to the columns
colnames(env_data)<-bands
#run the vif
vif<-vifstep(env_data)
#and let's find the layers that were excluded and drop them
excluded<-vif@excluded
predictors<-dropLayer(predictors,excluded)
#and let's just go ahead and see which layers were dropped.
NClayers<-names(predictors)
NClayers
#convert presence training data into a spatial points dataframe.
pres_train_SPDF<-SpatialPoints(pres_train)
crs(pres_train_SPDF) <- crs(wrld_simpl)
#Let's get the average distance between points (great circle distance--takes into account the curvature of the earth). spDists creates a matrix of distances between points. This includes zeros.
dist<-spDists(pres_train_SPDF,longlat = TRUE)
#replace the zeros with NA
dist[dist == 0]<-NA
#and calculate the mean--this is the average distance between points...the result will be in kilometers, but we need to convert it to meters so we multiply by 1000
dist<-1000*mean(dist, na.rm=TRUE)
#now we are going to make circles using the average distance between points as the diameter.
x <- circles(pres_train_SPDF, d=dist, lonlat=TRUE)
#and convert those into polygons
pol <- polygons(x)
#and draw a number of samples from that approximately three times the number of presence points. We'll chop that down at the end.
samp1 <- spsample(pol, nrow(pres_train)*3, type='random', iter=25)
#and get the cell numbers from the raster stack (right to left, up to down)
cells <- cellFromXY(predictors, samp1)
#and transform each of those to the center of its cell.
abs_train <- xyFromCell(predictors, cells)
#You'll get a warning saying that your CRS object has lost a comment. This is unimportant and can be ignored.
pres_train_data<-extract(predictors,pres_train)
complete<-complete.cases(pres_train_data)
pres_train_data<-pres_train_data[complete,]
pres_train_data<-cbind(pres_train_data,1)
abs_train_data<-extract(predictors,abs_train)
#remove rows with NA values
complete<-complete.cases(abs_train_data)
abs_train_data<-abs_train_data[complete,]
#and select a number of rows equal to the presence training data
abs_train_data<-abs_train_data[1:nrow(pres_train_data),]
#and add a column of zeros to the end.
abs_train_data<-cbind(abs_train_data,0)
#put the two matrices together and name the colmns
train_data<-rbind(pres_train_data,abs_train_data)
colnames(train_data)<-c(names(predictors),"pa")
train_data<-as.data.frame(train_data)
colnames(train_data)
NClayers
gam <- gam(pa ~ Mean_durnal_temp_range + Temp_Seasonality + MaxTemp_WarmestWeek +
Mean_temp_wettest_q + Ann_.precip + Precip_Seasonality + Precip_warmest_q + Hghest_weekly_rad + Rad_driest_q + Rad_coldest_q+ Moisture_seasonality + Mean_moisture_coldest_q + Elev + human_impact,                      ,
family = binomial(link = "logit"), data=train_data)
summary(gam)
GAMpreds <- predict(predictors, gam, type = 'response')
writeRaster(GAMpreds, filename = paste0(genus,"_",species,"_GAM.tif"), overwrite=TRUE)
plot(GAMpreds, main=c(genus,species,'GAM/Binary'),col=warm(100), zlim=c(0,1))
points(pres_test, col='white', cex =.4, pch=3)
samp1 <- spsample(pol, 10000, type='random', iter=25)
#and get the cell numbers from the raster stack (right to left, up to down)
cells <- cellFromXY(predictors, samp1)
#and transform each of those to the center of its cell.
background_train <- xyFromCell(predictors, cells)
#You'll get a warning saying that your CRS object has lost a comment. This is unimportant and can be ignored.
Sys.setenv(JAVA_HOME='/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home')
maxent()
me_model <- maxent(predictors, pres_train, a=background_train)
knitr::opts_chunk$set(echo = TRUE)
library(dismo)
library(sp)
library(raster)
library(stats)
library(dplyr)
library(knitr)
library(rgeos)
library(maptools)
library(rgdal)
library(ecospat)
library(usdm)
library(mgcv)
genus<-"Autographa"
species<-"gamma"
sdmdata<-read.csv(file=paste0("Autographa gamma clean.csv"))
##and visualize the data
#first lets get the extent of the data (the coordinates of the smallest box needed to encapsulate the data)  To do this I first need to convert sdmdata into a spatial points dataframe with the same crs as "wrldsmpl", a giant spatial polygons data frame available from maptools
sdmdataframe<-data.frame(sdmdata)
data(wrld_simpl)
coordinates(sdmdataframe) <- ~lon+lat
crs(sdmdataframe) <- crs(wrld_simpl)
#And then extract the extent
e<-extent(sdmdataframe)
xmin<-xmin(e)
xmax<-xmax(e)
ymin<-ymin(e)
ymax<-ymax(e)
# and then plot a map and add the points from sdmdata
plot(wrld_simpl, xlim=c(xmin,xmax), ylim=c(ymin,ymax), axes=TRUE, col="light yellow")
box()
points(sdmdata$lon, sdmdata$lat, col='red', cex=0.75)
#let's make sdmdata into a dataframe
data(wrld_simpl)
coordinates(sdmdata) <- ~lon+lat
crs(sdmdata) <- crs(wrld_simpl)
#let's extract just the coordinates
presence <- coordinates(sdmdata)
#First we'll make a random list of integers from 1-5 as long as our presence data. Setting the seed results in a repeatable random process
set.seed(0)
#now make a list as long as the number of rows in presence consisting of a random series of integers from 1-5
group <- kfold(presence, 5)
#Then we want to use this to retrieve the number of the rows in the presence data that are associated with the number 1 in our group index.
test_indices <- as.integer(row.names(presence[group == 1, ]))
#and create a new list of coordinates including only those rows that are NOT in test indices. These are all the row numbers NOT corresponding with the test_indices (which is ~80% of the data).
pres_train <- presence[-test_indices,]
#and those that do correspond with test indices (20%) of the data
pres_test <- presence[group ==1,]
#first presdata_train
outdata<-data.frame(pres_train)
colnames(outdata)<-c("lon","lat")
write.csv(outdata, file=paste0(genus,"_",species,"_train.csv"), row.names=FALSE)
#and then presdata_test
outdata<-data.frame(pres_test)
colnames(outdata)<-c("lon","lat")
write.csv(outdata, file=paste0(genus,"_",species,"_test.csv"), row.names=FALSE)
predictors<-stack('Climond_elev_HI.tif')
bands<-c("Ann_mean_temp",	"Mean_durnal_temp_range",	"Isothermality",	"Temp_Seasonality",	"MaxTemp_WarmestWeek",	"MinTemp_ColdestWeek",	"Temp_Annual_Range",	"Mean_temp_wettest_q",	"Mean_temp_driest_q",	"Mean_temp_warmiest_q",	"Mean_temp_coldest_q",	"Ann_ precip",	"Precip_driest_week",	"Precip_wettest_week",	"Precip_Seasonality",	"Precip_wettest_q",	"Precip_driest_q",	"Precip_warmest_q",	"Precip_coldest_q",	"Ann_mean_rad",	"Hghest_weekly_rad",	"Lowest_weekly_rad",	"Rad_seasonality",	"Rad_wettest_q",	"Rad_driest_q",	"Rad_warmest_q",	"Rad_coldest_q",	"Ann_mean_moisture",	"Highsets_weekly_moisture",	"Lowest_weekly_moisture",	"Moisture_seasonality",	"Mean_moisture_wettest_q",	"Mean_moisture_driest_q",	"Mean_moisture_warmest_q",	"Mean_moisture_coldest_q",	"Elev", 'human_impact')
names(predictors)<-bands
cool<-colorRampPalette(c('gray','green','dark green',"blue"))
warm<-colorRampPalette(c('yellow', 'orange', 'red', 'brown', 'black'))
plot(predictors[["Ann_mean_temp"]], col=warm(100))
#extract environmental data using the points in sdmdata
env_data<-extract(predictors,sdmdata)
#give names to the columns
colnames(env_data)<-bands
#run the vif
vif<-vifstep(env_data)
#and let's find the layers that were excluded and drop them
excluded<-vif@excluded
predictors<-dropLayer(predictors,excluded)
#and let's just go ahead and see which layers were dropped.
NClayers<-names(predictors)
NClayers
#convert presence training data into a spatial points dataframe.
pres_train_SPDF<-SpatialPoints(pres_train)
crs(pres_train_SPDF) <- crs(wrld_simpl)
#Let's get the average distance between points (great circle distance--takes into account the curvature of the earth). spDists creates a matrix of distances between points. This includes zeros.
dist<-spDists(pres_train_SPDF,longlat = TRUE)
#replace the zeros with NA
dist[dist == 0]<-NA
#and calculate the mean--this is the average distance between points...the result will be in kilometers, but we need to convert it to meters so we multiply by 1000
dist<-1000*mean(dist, na.rm=TRUE)
#now we are going to make circles using the average distance between points as the diameter.
x <- circles(pres_train_SPDF, d=dist, lonlat=TRUE)
#and convert those into polygons
pol <- polygons(x)
#and draw a number of samples from that approximately three times the number of presence points. We'll chop that down at the end.
samp1 <- spsample(pol, nrow(pres_train)*3, type='random', iter=25)
#and get the cell numbers from the raster stack (right to left, up to down)
cells <- cellFromXY(predictors, samp1)
#and transform each of those to the center of its cell.
abs_train <- xyFromCell(predictors, cells)
#You'll get a warning saying that your CRS object has lost a comment. This is unimportant and can be ignored.
pres_train_data<-extract(predictors,pres_train)
complete<-complete.cases(pres_train_data)
pres_train_data<-pres_train_data[complete,]
pres_train_data<-cbind(pres_train_data,1)
abs_train_data<-extract(predictors,abs_train)
#remove rows with NA values
complete<-complete.cases(abs_train_data)
abs_train_data<-abs_train_data[complete,]
#and select a number of rows equal to the presence training data
abs_train_data<-abs_train_data[1:nrow(pres_train_data),]
#and add a column of zeros to the end.
abs_train_data<-cbind(abs_train_data,0)
#put the two matrices together and name the colmns
train_data<-rbind(pres_train_data,abs_train_data)
colnames(train_data)<-c(names(predictors),"pa")
train_data<-as.data.frame(train_data)
colnames(train_data)
NClayers
gam <- gam(pa ~ Mean_durnal_temp_range + Temp_Seasonality + MaxTemp_WarmestWeek +
Mean_temp_wettest_q + Ann_.precip + Precip_Seasonality + Precip_warmest_q + Hghest_weekly_rad + Rad_driest_q + Rad_coldest_q+ Moisture_seasonality + Mean_moisture_coldest_q + Elev + human_impact,                      ,
family = binomial(link = "logit"), data=train_data)
summary(gam)
GAMpreds <- predict(predictors, gam, type = 'response')
writeRaster(GAMpreds, filename = paste0(genus,"_",species,"_GAM.tif"), overwrite=TRUE)
plot(GAMpreds, main=c(genus,species,'GAM/Binary'),col=warm(100), zlim=c(0,1))
points(pres_test, col='white', cex =.4, pch=3)
samp1 <- spsample(pol, 10000, type='random', iter=25)
#and get the cell numbers from the raster stack (right to left, up to down)
cells <- cellFromXY(predictors, samp1)
#and transform each of those to the center of its cell.
background_train <- xyFromCell(predictors, cells)
#You'll get a warning saying that your CRS object has lost a comment. This is unimportant and can be ignored.
Sys.setenv(JAVA_HOME='/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home')
maxent()
me_model <- maxent(predictors, pres_train, a=background_train)
background_train<-background_train[!is.na(background_train)]
samp1 <- spsample(pol, 10000, type='random', iter=25)
#and get the cell numbers from the raster stack (right to left, up to down)
cells <- cellFromXY(predictors, samp1)
#and transform each of those to the center of its cell.
background_train <- xyFromCell(predictors, cells)
background_train<-background_train[!is.na(background_train)]
#You'll get a warning saying that your CRS object has lost a comment. This is unimportant and can be ignored.
MEpreds<-predict(predictors, me_model, type='response')
maxent()
me_model <- maxent(predictors, pres_train, a=background_train)
#and transform each of those to the center of its cell.
background_train <- xyFromCell(predictors, cells)
background_train<-background_train[!is.na(background_train)]
#and transform each of those to the center of its cell.
background_train <- xyFromCell(predictors, cells)
View(background_train)
background_train<-as.matrix(background_train)
background_train <- xyFromCell(predictors, cells)
background_train<-background_train[!is.na(background_train)]
background_train<-as.matrix(background_train)
#and transform each of those to the center of its cell.
background_train <- xyFromCell(predictors, cells)
background_train <- xyFromCell(predictors, cells)
background_train<-background_train[!is.na(background_train)]
background_train<-as.matrix(background_train)
View(background_train)
background_train <- xyFromCell(predictors, cells)
background_train<-background_train[!is.na(background_train)]
background_train<-as.matrix(background_train,2)
#and transform each of those to the center of its cell.
background_train <- xyFromCell(predictors, cells)
maxent()
me_model <- maxent(predictors, pres_train, a=background_train)
library(dismo)
library(sp)
library(raster)
library(stats)
library(dplyr)
library(knitr)
library(rgeos)
library(maptools)
library(rgdal)
library(ecospat)
library(usdm)
library(mgcv)
genus<-"Helicoverpa"
species<-"armigera"
sdmdata<-read.csv(file=paste0(genus,"_",species,"_clean.csv")
##and visualize the data
#first lets get the extent of the data (the coordinates of the smallest box needed to encapsulate the data)  To do this I first need to convert sdmdata into a spatial points dataframe with the same crs as "wrldsmpl", a giant spatial polygons data frame available from maptools
sdmdataframe<-data.frame(sdmdata)
sdmdata<-read.csv(file=paste0("Helicoverpa armigera.CLEAN.csv")
##and visualize the data
#first lets get the extent of the data (the coordinates of the smallest box needed to encapsulate the data)  To do this I first need to convert sdmdata into a spatial points dataframe with the same crs as "wrldsmpl", a giant spatial polygons data frame available from maptools
sdmdataframe<-data.frame(sdmdata)
sdmdata<-read.csv(file=paste0("Helicoverpa armigera.CLEAN.csv")
##and visualize the data
#first lets get the extent of the data (the coordinates of the smallest box needed to encapsulate the data)  To do this I first need to convert sdmdata into a spatial points dataframe with the same crs as "wrldsmpl", a giant spatial polygons data frame available from maptools
sdmdataframe<-data.frame(sdmdata)
sdmdata<-read.csv(file=paste0("Helicoverpa armigera.CLEAN.csv")
sdmdata<-read.csv(file=paste0("Helicoverpa armigera.CLEAN.csv"))
sdmdata<-read.csv("Helicoverpa armigera.CLEAN.csv")
setwd("C:/Users/Nico/Desktop/Spring 2022/BRT and Max Modeling/Helicoverpa armigera")
sdmdata<-read.csv(file=paste0("Helicoverpa armigera.CLEAN.csv"))
sdmdata<-read.csv(file=paste0("Helicoverpa armigera.CLEAN.csv"))
sdmdata<-read.csv("Helicoverpa armigera.CLEAN.csv")
sdmdata<-read.csv(file=paste0("Helicoverpa armigera.csv"))
setwd("C:/Users/Nico/Desktop/Spring 2022/BRT and Max Modeling/Helicoverpa armigera")
sdmdata<-read.csv(file=paste0("Helicoverpa armigera.csv"))
sdmdata<-read.csv(file=paste0("Autographa gamma clean.csv"))
sdmdata <- gbif("Helicoverpa", "armigera*", geo=FALSE)
sdmdataframe<-data.frame(sdmdata)
data(wrld_simpl)
coordinates(sdmdataframe) <- ~lon+lat
coordinates(sdmdataframe) <- ~lon+lat
sdmdata <- subset(sdmdata, !is.na(lon) & !is.na(lat))
knitr::opts_chunk$set(echo = TRUE)
library(dismo)
library(rgeos)
library(maptools)
library(raster)
library(rJava)
library(shades)
points(sdmdata$lon, sdmdata$lat, col='red', cex=0.75)
dups <-duplicated(sdmdata[ c('lon', 'lat')])
sdmdata<-sdmdata[!dups,]
coordinates(sdmdataframe) <- ~lon+lat
#and visualize the data
#first lets get the extent of the data (the coordinates of the smallest box needed to encapsulate the data)  To do this I first need to convert sdmdata into a spatial points dataframe with the same crs as "wrldsmpl", a giant spatial polygons data frame available from maptools
sdmdataframe<-data.frame(sdmdata)
sdmdataframe<-data.frame(sdmdata)
data(wrld_simpl)
coordinates(sdmdataframe) <- ~lon+lat
crs(sdmdataframe) <- crs(wrld_simpl)
#And then extract the extent
e<-extent(sdmdataframe)
xmin<-xmin(e)
xmax<-xmax(e)
ymin<-ymin(e)
ymax<-ymax(e)
# and then plot a map and add the points from sdmdata
plot(wrld_simpl, xlim=c(xmin,xmax), ylim=c(ymin,ymax), axes=TRUE, col="light yellow")
box()
points(sdmdata$lon, sdmdata$lat, col='red', cex=0.75)
#let's make sdmdata into a dataframe
data(wrld_simpl)
coordinates(sdmdata) <- ~lon+lat
crs(sdmdata) <- crs(wrld_simpl)
#let's extract just the coordinates
presence <- coordinates(sdmdata)
#First we'll make a random list of integers from 1-5 as long as our presence data. Setting the seed results in a repeatable random process
set.seed(0)
#now make a list as long as the number of rows in presence consisting of a random series of integers from 1-5
group <- kfold(presence, 5)
#Then we want to use this to retrieve the number of the rows in the presence data that are associated with the number 1 in our group index.
test_indices <- as.integer(row.names(presence[group == 1, ]))
#and create a new list of coordinates including only those rows that are NOT in test indices. These are all the row numbers NOT corresponding with the test_indices (which is ~80% of the data).
pres_train <- presence[-test_indices,]
#and those that do correspond with test indices (20%) of the data
pres_test <- presence[group ==1,]
#first presdata_train
outdata<-data.frame(pres_train)
colnames(outdata)<-c("lon","lat")
write.csv(outdata, file=paste0(genus,"_",species,"_train.csv"), row.names=FALSE)
#and then presdata_test
outdata<-data.frame(pres_test)
colnames(outdata)<-c("lon","lat")
write.csv(outdata, file=paste0(genus,"_",species,"_test.csv"), row.names=FALSE)
predictors<-stack('Climond_elev_HI.tif')
bands<-c("Ann_mean_temp",	"Mean_durnal_temp_range",	"Isothermality",	"Temp_Seasonality",	"MaxTemp_WarmestWeek",	"MinTemp_ColdestWeek",	"Temp_Annual_Range",	"Mean_temp_wettest_q",	"Mean_temp_driest_q",	"Mean_temp_warmiest_q",	"Mean_temp_coldest_q",	"Ann_ precip",	"Precip_driest_week",	"Precip_wettest_week",	"Precip_Seasonality",	"Precip_wettest_q",	"Precip_driest_q",	"Precip_warmest_q",	"Precip_coldest_q",	"Ann_mean_rad",	"Hghest_weekly_rad",	"Lowest_weekly_rad",	"Rad_seasonality",	"Rad_wettest_q",	"Rad_driest_q",	"Rad_warmest_q",	"Rad_coldest_q",	"Ann_mean_moisture",	"Highsets_weekly_moisture",	"Lowest_weekly_moisture",	"Moisture_seasonality",	"Mean_moisture_wettest_q",	"Mean_moisture_driest_q",	"Mean_moisture_warmest_q",	"Mean_moisture_coldest_q",	"Elev", 'human_impact')
names(predictors)<-bands
cool<-colorRampPalette(c('gray','green','dark green',"blue"))
warm<-colorRampPalette(c('yellow', 'orange', 'red', 'brown', 'black'))
plot(predictors[["Ann_mean_temp"]], col=warm(100))
#extract environmental data using the points in sdmdata
env_data<-extract(predictors,sdmdata)
#give names to the columns
colnames(env_data)<-bands
#run the vif
vif<-vifstep(env_data)
#and let's find the layers that were excluded and drop them
excluded<-vif@excluded
predictors<-dropLayer(predictors,excluded)
#and let's just go ahead and see which layers were dropped.
NClayers<-names(predictors)
NClayers
#convert presence training data into a spatial points dataframe.
pres_train_SPDF<-SpatialPoints(pres_train)
crs(pres_train_SPDF) <- crs(wrld_simpl)
#Let's get the average distance between points (great circle distance--takes into account the curvature of the earth). spDists creates a matrix of distances between points. This includes zeros.
dist<-spDists(pres_train_SPDF,longlat = TRUE)
#replace the zeros with NA
dist[dist == 0]<-NA
#and calculate the mean--this is the average distance between points...the result will be in kilometers, but we need to convert it to meters so we multiply by 1000
dist<-1000*mean(dist, na.rm=TRUE)
#now we are going to make circles using the average distance between points as the diameter.
x <- circles(pres_train_SPDF, d=dist, lonlat=TRUE)
